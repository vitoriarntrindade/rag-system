# Sistema RAG

Um sistema de **Retrieval-Augmented Generation (RAG)** modular e pronto para produÃ§Ã£o, com ingestÃ£o flexÃ­vel de documentos, arquitetura escalÃ¡vel e suporte a mÃºltiplos formatos de documentos.

---

## ğŸš€ Funcionalidades

- **Suporte a mÃºltiplos formatos de documentos**: PDF, TXT, DOCX, DOC, Markdown  
- **Arquitetura modular**: SeparaÃ§Ã£o clara de responsabilidades com mÃ³dulos dedicados  
- **IngestÃ£o flexÃ­vel de documentos**: Arquivos Ãºnicos, diretÃ³rios ou processamento em lote  
- **RecuperaÃ§Ã£o baseada em vetores**: Busca eficiente por similaridade usando ChromaDB  
- **GeraÃ§Ã£o com LLM**: Modelos OpenAI GPT para respostas inteligentes  
- **Interface CLI**: Ferramentas de linha de comando fÃ¡ceis de usar  
- **Pronto para produÃ§Ã£o**: Logging completo, tratamento de erros e gerenciamento de configuraÃ§Ã£o  
- **Gerenciamento seguro de chave de API**: InjeÃ§Ã£o explÃ­cita de API Token  

---

## ğŸ“‹ Requisitos

- Python 3.9+
- Chave de API da OpenAI

---

## ğŸ”§ InstalaÃ§Ã£o

### OpÃ§Ã£o 1: Desenvolvimento Local

```bash
    git clone https://github.com/vitoriarntrindade/rag-system.git
    cd rag-system
    
    python -m venv .venv
    source .venv/bin/activate  # Windows: .venv\Scripts\activate
    
    pip install -r requirements.txt
```

### OpÃ§Ã£o 2: Como Biblioteca (lib)

```bash
    pip install git+https://github.com/vitoriarntrindade/rag-system.git
```

---

## âš™ï¸ ConfiguraÃ§Ã£o

### ConfiguraÃ§Ã£o da Chave de API (ObrigatÃ³ria)

O sistema requer uma chave de API da OpenAI. **Ela deve ser fornecida explicitamente** â€” nunca faÃ§a hardcode da chave no cÃ³digo-fonte.

#### MÃ©todo 1: VariÃ¡vel de Ambiente (Recomendado)

```bash
    export OPENAI_API_KEY='your-api-key-here'
    echo "OPENAI_API_KEY=your-api-key-here" > .env
```

#### MÃ©todo 2: Carregar do .env no CÃ³digo

```python
from dotenv import load_dotenv
import os

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

from src.rag_pipeline import RAGPipeline
pipeline = RAGPipeline(openai_api_key=api_key)
```

#### MÃ©todo 3: InjeÃ§Ã£o Direta (somente para testes)

```python
from src.rag_pipeline import RAGPipeline
pipeline = RAGPipeline(openai_api_key="sk-your-key-here")
```

### ğŸ› ï¸ ExplicaÃ§Ã£o das ConfiguraÃ§Ãµes

Abaixo estÃ£o as variÃ¡veis de ambiente disponÃ­veis no projeto e o propÃ³sito de cada uma:
### ğŸ› ï¸ ExplicaÃ§Ã£o das ConfiguraÃ§Ãµes

Abaixo estÃ£o as variÃ¡veis de ambiente disponÃ­veis no projeto e o propÃ³sito de cada uma:

```
# ============================
# ğŸ¤– ConfiguraÃ§Ãµes da OpenAI
# ============================

# ğŸ§  Modelo utilizado para gerar os embeddings (vetores) dos documentos.
# Esses vetores sÃ£o usados na busca semÃ¢ntica por similaridade.
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# ğŸ’¬ Modelo de linguagem utilizado para gerar as respostas finais (LLM).
# ResponsÃ¡vel por transformar os trechos recuperados em respostas naturais.
OPENAI_CHAT_MODEL=gpt-3.5-turbo

# ğŸ¨ Controla o nÃ­vel de criatividade das respostas do modelo.
# Valores mais baixos tornam as respostas mais objetivas e determinÃ­sticas.
OPENAI_TEMPERATURE=0.3


# ============================
# âœ‚ï¸ Processamento de Texto
# ============================

# ğŸ“ Tamanho mÃ¡ximo de cada chunk (trecho) de texto gerado a partir dos documentos.
# Valores maiores preservam mais contexto, valores menores melhoram a precisÃ£o da busca.
CHUNK_SIZE=1000

# ğŸ” Quantidade de caracteres que se sobrepÃµem entre chunks consecutivos.
# Ajuda a evitar perda de contexto entre trechos.
CHUNK_OVERLAP=200


# ============================
# ğŸ” RecuperaÃ§Ã£o (Retrieval)
# ============================

# ğŸ—‚ï¸ NÃºmero de documentos/trechos mais relevantes que serÃ£o recuperados
# para responder a uma pergunta.
RETRIEVAL_TOP_K=5

# ğŸ§­ Tipo de estratÃ©gia de busca utilizada no vector store.
# 'similarity' retorna os vetores mais prÃ³ximos semanticamente da pergunta.
RETRIEVAL_SEARCH_TYPE=similarity


# ============================
# ğŸ“‹ Logging
# ============================

# ğŸ§¾ Define o nÃ­vel de detalhamento dos logs da aplicaÃ§Ã£o.
# Exemplos: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# ğŸ’¾ Indica se os logs devem ser gravados em arquivo alÃ©m da saÃ­da no console.
LOG_TO_FILE=true

````

---

## ğŸ¯ Uso

### Uso via CLI

```
bash
    export OPENAI_API_KEY='your-key-here'
```

#### IngestÃ£o de Documentos

```bash
    python main.py ingest --file data/document.pdf
    python main.py ingest --directory data/
    python main.py ingest --directory data/ --file-types pdf txt
    python main.py ingest --directory data/ --no-recursive
    python main.py ingest --file data/document.pdf --force
```

#### Consultas

```bash
    python main.py query "Qual Ã© o tema principal?"
    python main.py query "Explique o conceito" --no-sources
```

#### Chat Interativo

```bash
    python main.py chat
```

---

## ğŸ“¦ Uso do RAG System como Biblioteca

O **RAG System** foi projetado para funcionar como um **componente reutilizÃ¡vel**, podendo ser facilmente integrado em outros projetos Python, como:

- Chatbots
- APIs backend (FastAPI / Flask)
- Ferramentas internas
- Sistemas de busca semÃ¢ntica
- AplicaÃ§Ãµes corporativas

### Exemplo: IntegraÃ§Ã£o em um Projeto Python

```python
from pathlib import Path
from src.rag_pipeline import RAGPipeline

pipeline = RAGPipeline(openai_api_key="YOUR_API_KEY")

pipeline.ingest_documents(
    directory=Path("data/"),
    file_types=[".pdf", ".txt"],
    recursive=True
)

answer, sources = pipeline.query("O que Ã© mudanÃ§a climÃ¡tica?")
print(answer)
```

---

### Exemplo: Uso em um Chatbot

```python
from src.rag_pipeline import RAGPipeline

pipeline = RAGPipeline(openai_api_key="YOUR_API_KEY")

while True:
    question = input("UsuÃ¡rio: ")
    if question.lower() in {"sair", "exit", "quit"}:
        break

    answer, _ = pipeline.query(question)
    print(f"Bot: {answer}")
```

---

### Exemplo: IntegraÃ§Ã£o com FastAPI

```python
from fastapi import FastAPI
from pydantic import BaseModel
from src.rag_pipeline import RAGPipeline

app = FastAPI(title="RAG API")

pipeline = RAGPipeline(openai_api_key="YOUR_API_KEY")

class QuestionRequest(BaseModel):
    question: str

class AnswerResponse(BaseModel):
    answer: str

@app.post("/ask", response_model=AnswerResponse)
def ask_rag(request: QuestionRequest):
    answer, _ = pipeline.query(request.question)
    return AnswerResponse(answer=answer)
```

---

## ğŸ—ï¸ Arquitetura

```
rag/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ document_loader.py
â”‚   â”œâ”€â”€ text_processor.py
â”‚   â”œâ”€â”€ vector_store.py
â”‚   â”œâ”€â”€ retriever.py
â”‚   â”œâ”€â”€ generator.py
â”‚   â”œâ”€â”€ rag_pipeline.py
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ logger.py
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py
â”œâ”€â”€ data/
â”œâ”€â”€ db/
â”œâ”€â”€ logs/
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ .gitignore
```

---

## ğŸ“¦ Formatos Suportados

| Formato | ExtensÃ£o |
|--------|----------|
| PDF | .pdf |
| Texto | .txt |
| Word | .docx, .doc |
| Markdown | .md |

---

## ğŸ”’ Boas PrÃ¡ticas de SeguranÃ§a

- Use variÃ¡veis de ambiente
- Nunca versione arquivos `.env`
- Use secret managers em produÃ§Ã£o
- FaÃ§a rotaÃ§Ã£o periÃ³dica de chaves

---

## ğŸ§ª Testes

A suÃ­te de testes cobre:

- `test_document_loader.py`: Carregamento de documentos, listagem de arquivos e operaÃ§Ãµes com diretÃ³rios  
- `test_text_processor.py`: Funcionalidade de chunking e divisÃ£o de texto  
- `test_vector_store.py`: Armazenamento vetorial e operaÃ§Ãµes de busca por similaridade  
- `test_retriever.py`: Funcionalidade de recuperaÃ§Ã£o de documentos  
- `test_generator.py`: GeraÃ§Ã£o de respostas via LLM e formataÃ§Ã£o de prompts  
- `test_rag_pipeline.py`: OrquestraÃ§Ã£o end-to-end do pipeline RAG  
- `test_settings.py`: Gerenciamento e validaÃ§Ã£o de configuraÃ§Ãµes  
- `test_logger.py`: ConfiguraÃ§Ã£o e setup de logging  

```bash
    pytest tests/
    pytest --cov=src tests/
```